
import sys
import os
import time
import json
import re
import argparse
from multiprocessing.dummy import Pool as ThreadPool
import requests

INTELLIGENCE_SEARCH_URL = 'https://www.virustotal.com/intelligence/search/programmatic/'
BEHAVIOR_URL            = 'https://www.virustotal.com/vtapi/v2/file/report'
THREADS_NUM             = 50
API_CAP_PER_MIN         = 200


def chunks(l, n):
    """Yield successive n-sized chunks from l."""
    for i in range(0, len(l), n):
        yield l[i:i + n]


def main():

    parser = argparse.ArgumentParser(description='Download behavioral data from VirusTotal.')
    parser.add_argument('hash_file', type=str, help='Text file containing executable hashes.')
    parser.add_argument('output_folder', type=str, help='Target output folder to store downloaded behavioral data.')
    parser.add_argument('apikey', type=str, help='VirusTotal API key')
    args = parser.parse_args()

    valid_hash = re.compile(r'[0-9a-fA-F]{32,64}')

    TARGET_DIR = args.output_folder

    filename_list = []
    hash_list = []

    with open(args.hash_file, 'r') as fi:
        total_hashes = fi.read().split('\n')
        for each_hash in total_hashes:
            if each_hash:
                mal_name, mal_hash = each_hash.split(',')
                filename = ["{}/{}_{}.json".format(TARGET_DIR, mal_name, mal_hash)]
                filename_list.append(filename)
                hash_list.append(mal_hash)
                if not valid_hash.match(mal_hash):
                    print("\nInvalid hash --> \"{}\"!\n\nVirustotal only accepts MD5, SHA1 and SHA256 hashes.\n".format(mal_hash))
                    sys.exit(0)

    print('')
    print("[+] Got total of {} hashes".format(len(total_hashes)))
    print("[+] Downloading behaviour data, putting into {} folder".format(TARGET_DIR))

    if not os.path.exists(TARGET_DIR):
        os.makedirs(TARGET_DIR)

    argv = list(zip(hash_list, filename_list))
    argv_chunk = chunks(argv, THREADS_NUM)

    def fetch_behavior(each_hash, file_path):
        params = {'apikey': args.apikey, 'resource': each_hash, 'allinfo': 1}
        response = requests.get(BEHAVIOR_URL, params=params)
        try:
            json_data = response.json()
            if 'additional_info' in json_data:
                with open(file_path, 'w') as f:
                    json.dump(json_data, f, sort_keys=True, indent=4)
        except BaseException as error:
            print(str(error))

    # start multithread downloading
    start_time  = time.time()
    total_fetch = THREADS_NUM
    cap_limit   = total_fetch
    for each_chunk in argv_chunk:
        if cap_limit > API_CAP_PER_MIN:
            print("  [-] Time cap reached... sleeping for 1 minute before continuing...")
            time.sleep(65)
            cap_limit = 0
        pool = ThreadPool(THREADS_NUM)
        pool.starmap(fetch_behavior, each_chunk)
        pool.close()
        pool.join()
        print("  [-] Fetched {} behaviors data...".format(total_fetch))
        total_fetch += THREADS_NUM
        cap_limit   += THREADS_NUM

    process_time = time.time() - start_time
    print("\nFinish! Process took %d second(s)\n" % process_time)


if __name__ == '__main__':
    main()
